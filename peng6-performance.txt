
--------------------------------------------------
(A) BASE-MLP - Hyperparameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              random_state=0)>
--------------------------------------------------
(B) Confusion Matrix:
[[30  3  6]
 [ 4  6  0]
 [ 1  0 17]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.86      0.77      0.81        39
   Chinstrap       0.67      0.60      0.63        10
      Gentoo       0.74      0.94      0.83        18

    accuracy                           0.79        67
   macro avg       0.75      0.77      0.76        67
weighted avg       0.80      0.79      0.79        67

(D) Accuracy: 0.7910447761194029
    Macro-average F1: 0.7572193502873862
    Weighted-average F1: 0.7890185128895301

--------------------------------------------------
(A) TOP-MLP - Hyperparameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 100), 'random_state': 0, 'solver': 'adam'}
--------------------------------------------------
(B) Confusion Matrix:
[[29  4  6]
 [ 2  8  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.94      0.74      0.83        39
   Chinstrap       0.67      0.80      0.73        10
      Gentoo       0.75      1.00      0.86        18

    accuracy                           0.82        67
   macro avg       0.78      0.85      0.80        67
weighted avg       0.85      0.82      0.82        67

(D) Accuracy: 0.8208955223880597
    Macro-average F1: 0.8043290043290043
    Weighted-average F1: 0.8211281256057376

--------------------------------------------------
(A) BASE-MLP - Hyperparameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              random_state=0)>
--------------------------------------------------
(B) Confusion Matrix:
[[30  3  6]
 [ 4  6  0]
 [ 1  0 17]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.86      0.77      0.81        39
   Chinstrap       0.67      0.60      0.63        10
      Gentoo       0.74      0.94      0.83        18

    accuracy                           0.79        67
   macro avg       0.75      0.77      0.76        67
weighted avg       0.80      0.79      0.79        67

(D) Accuracy: 0.7910447761194029
    Macro-average F1: 0.7572193502873862
    Weighted-average F1: 0.7890185128895301

--------------------------------------------------
(A) TOP-MLP - Hyperparameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 100), 'random_state': 0, 'solver': 'adam'}
--------------------------------------------------
(B) Confusion Matrix:
[[29  4  6]
 [ 2  8  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.94      0.74      0.83        39
   Chinstrap       0.67      0.80      0.73        10
      Gentoo       0.75      1.00      0.86        18

    accuracy                           0.82        67
   macro avg       0.78      0.85      0.80        67
weighted avg       0.85      0.82      0.82        67

(D) Accuracy: 0.8208955223880597
    Macro-average F1: 0.8043290043290043
    Weighted-average F1: 0.8211281256057376

--------------------------------------------------
(A) BASE-DTC - Hyperparameters: <bound method BaseEstimator.get_params of DecisionTreeClassifier(criterion='entropy')>
--------------------------------------------------
(B) Confusion Matrix:
[[38  1  0]
 [ 3  7  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.93      0.97      0.95        39
   Chinstrap       0.88      0.70      0.78        10
      Gentoo       1.00      1.00      1.00        18

    accuracy                           0.94        67
   macro avg       0.93      0.89      0.91        67
weighted avg       0.94      0.94      0.94        67

(D) Accuracy: 0.9402985074626866
    Macro-average F1: 0.9092592592592593
    Weighted-average F1: 0.9377280265339968

--------------------------------------------------
(A) TOP-DTC - Hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
--------------------------------------------------

--------------------------------------------------
(A) BASE-DTC - Hyperparameters: <bound method BaseEstimator.get_params of DecisionTreeClassifier(criterion='entropy')>
--------------------------------------------------
(B) Confusion Matrix:
[[38  1  0]
 [ 3  7  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.93      0.97      0.95        39
   Chinstrap       0.88      0.70      0.78        10
      Gentoo       1.00      1.00      1.00        18

    accuracy                           0.94        67
   macro avg       0.93      0.89      0.91        67
weighted avg       0.94      0.94      0.94        67

(D) Accuracy: 0.9402985074626866
    Macro-average F1: 0.9092592592592593
    Weighted-average F1: 0.9377280265339968

--------------------------------------------------
(A) TOP-DTC - Hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}
--------------------------------------------------

--------------------------------------------------
(A) BASE-DTC - Hyperparameters: <bound method BaseEstimator.get_params of DecisionTreeClassifier(criterion='entropy')>
--------------------------------------------------
(B) Confusion Matrix:
[[38  1  0]
 [ 3  7  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.93      0.97      0.95        39
   Chinstrap       0.88      0.70      0.78        10
      Gentoo       1.00      1.00      1.00        18

    accuracy                           0.94        67
   macro avg       0.93      0.89      0.91        67
weighted avg       0.94      0.94      0.94        67

(D) Accuracy: 0.9402985074626866
    Macro-average F1: 0.9092592592592593
    Weighted-average F1: 0.9377280265339968

--------------------------------------------------
(A) TOP-DTC - Hyperparameters: {'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 5}
--------------------------------------------------
(B) Confusion Matrix:
[[39  0  0]
 [ 2  8  0]
 [ 1  0 17]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.93      1.00      0.96        39
   Chinstrap       1.00      0.80      0.89        10
      Gentoo       1.00      0.94      0.97        18

    accuracy                           0.96        67
   macro avg       0.98      0.91      0.94        67
weighted avg       0.96      0.96      0.95        67

(D) Accuracy: 0.9552238805970149
    Macro-average F1: 0.9410934744268079
    Weighted-average F1: 0.9541814735844586

--------------------------------------------------
(A) BASE-MLP - Hyperparameters: <bound method BaseEstimator.get_params of MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100),
              random_state=0)>
--------------------------------------------------
(B) Confusion Matrix:
[[30  3  6]
 [ 4  6  0]
 [ 1  0 17]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.86      0.77      0.81        39
   Chinstrap       0.67      0.60      0.63        10
      Gentoo       0.74      0.94      0.83        18

    accuracy                           0.79        67
   macro avg       0.75      0.77      0.76        67
weighted avg       0.80      0.79      0.79        67

(D) Accuracy: 0.7910447761194029
    Macro-average F1: 0.7572193502873862
    Weighted-average F1: 0.7890185128895301

--------------------------------------------------
(A) TOP-MLP - Hyperparameters: {'activation': 'logistic', 'hidden_layer_sizes': (100, 100), 'random_state': 0, 'solver': 'adam'}
--------------------------------------------------
(B) Confusion Matrix:
[[29  4  6]
 [ 2  8  0]
 [ 0  0 18]]
(C) Classification Report:
              precision    recall  f1-score   support

      Adelie       0.94      0.74      0.83        39
   Chinstrap       0.67      0.80      0.73        10
      Gentoo       0.75      1.00      0.86        18

    accuracy                           0.82        67
   macro avg       0.78      0.85      0.80        67
weighted avg       0.85      0.82      0.82        67

(D) Accuracy: 0.8208955223880597
    Macro-average F1: 0.8043290043290043
    Weighted-average F1: 0.8211281256057376
